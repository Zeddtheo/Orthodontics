# MeshSegNet åå¤„ç†è¯„ä¼°ä¿®å¤æŒ‡å—

## ğŸ“‹ é—®é¢˜è¯Šæ–­

### å½“å‰å®ç°çš„é—®é¢˜

1. **graphcut_refine å‡½æ•°**
   - âŒ ä¸æ˜¯çœŸæ­£çš„å›¾å‰²ç®—æ³•
   - âœ… åªæ˜¯åŸºäº k-NN çš„æ¦‚ç‡å¹³æ»‘
   - ğŸ“ ç°å·²æ·»åŠ æ³¨é‡Šè¯´æ˜

2. **svm_refine å‡½æ•°çš„è‡´å‘½ç¼ºé™·**
   - âŒ åœ¨**ä½åˆ†è¾¨ç‡**ç½‘æ ¼ä¸Šè®­ç»ƒå’Œé¢„æµ‹ï¼ˆN â‰ˆ 9000ï¼‰
   - âŒ æ²¡æœ‰ä¸Šé‡‡æ ·åˆ°**åŸå§‹é«˜åˆ†è¾¨ç‡**ç½‘æ ¼ï¼ˆN â‰ˆ 100kï¼‰
   - ğŸ“Š å¯¼è‡´æ‰€æœ‰ `post_*` æŒ‡æ ‡æ— æ•ˆ

3. **è¯„ä¼°æŒ‡æ ‡çš„é”™è¯¯**
   - âœ… `raw_*` æŒ‡æ ‡ï¼šæœ‰æ•ˆï¼ˆåœ¨ä½åˆ†è¾¨ç‡ä¸Šç›´æ¥é¢„æµ‹ï¼‰
   - âŒ `post_*` æŒ‡æ ‡ï¼š**æ— æ•ˆ**ï¼ˆæœªåœ¨é«˜åˆ†è¾¨ç‡ä¸Šè¯„ä¼°ï¼‰

---

## âœ… ç¬¬ä¸€éƒ¨åˆ†ï¼šçŸ­æœŸä¿®å¤ï¼ˆå·²å®Œæˆï¼‰

### ä¿®æ”¹1ï¼šgraphcut_refine å‡½æ•°æ·»åŠ è­¦å‘Šæ³¨é‡Š

**ä½ç½®**: `m1_train.py` Line ~145

**ä¿®æ”¹å†…å®¹**:
```python
def graphcut_refine(prob_np: np.ndarray, pos_mm_np: np.ndarray, beta: float = 30.0, k: int = 6, iterations: int = 1) -> np.ndarray:
    """
    NOTE: This is an iterative probability smoothing, an approximation of graph-cut's smoothness effect, 
    not a true energy-minimizing graph-cut. This function performs k-NN based probability smoothing 
    to mimic the spatial consistency constraint of graph-cut algorithms.
    """
```

### ä¿®æ”¹2ï¼šsvm_refine å‡½æ•°æ·»åŠ è­¦å‘Šæ³¨é‡Š

**ä½ç½®**: `m1_train.py` Line ~175

**ä¿®æ”¹å†…å®¹**:
```python
def svm_refine(pos_mm_np: np.ndarray, labels_np: np.ndarray) -> np.ndarray:
    """
    WARNING: This function performs SVM refinement on the SAME low-resolution mesh (N_low â‰ˆ 9000),
    NOT on the original high-resolution mesh (N_high â‰ˆ 100k) as described in the paper.
    To properly implement the paper's approach, this function should:
    1. Train SVM on low-res predictions (N_low)
    2. Predict on high-res original mesh (N_high) - CURRENTLY NOT IMPLEMENTED
    Therefore, post-processing metrics computed using this function are INVALID for paper comparison.
    """
```

### ä¿®æ”¹3ï¼šæ³¨é‡Šæ‰æ‰“å°è¾“å‡ºä¸­çš„ post_ æŒ‡æ ‡

**ä½ç½®**: `m1_train.py` Line ~415

**ä¿®æ”¹å†…å®¹**:
```python
# NOTE: Post-processed metrics (post_dsc, post_hd, etc.) are INVALID in current implementation
# because svm_refine does not perform true upsampling to original resolution.
# Focus on raw_ metrics for model evaluation.
print(
    f"Epoch {epoch}/{self.config.epochs} | "
    f"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | "
    f"Raw DSC: {raw_dsc_str}Â±{raw_dsc_std_str} | Raw SEN: {raw_sen_str}Â±{raw_sen_std_str} | "
    f"Raw PPV: {raw_ppv_str}Â±{raw_ppv_std_str} | Raw HD: {raw_hd_str}Â±{raw_hd_std_str} mm | "
    # Post-processing metrics commented out as they are invalid without proper upsampling:
    # f"Post DSC: {post_dsc_str}Â±{post_dsc_std_str} | Post SEN: {post_sen_str}Â±{post_sen_std_str} | "
    # f"Post PPV: {post_ppv_str}Â±{post_ppv_std_str} | Post HD: {post_hd_str}Â±{post_hd_std_str} mm | "
    f"Time: {epoch_time:.1f}s | Sec/scan: {sec_per_scan:.2f}s | PeakMem: {train_peak_mem:.1f}MB | LR: {current_lr:.6f}"
)
```

### å…³é”®å˜åŒ–

- âœ… æ‰€æœ‰è­¦å‘Šæ³¨é‡Šå·²æ·»åŠ 
- âœ… æ‰“å°è¾“å‡ºå·²ç®€åŒ–ï¼Œåªæ˜¾ç¤ºæœ‰æ•ˆçš„ `raw_*` æŒ‡æ ‡
- âœ… æ¨¡å‹ä¿å­˜é€»è¾‘å·²æ­£ç¡®é”šå®šåœ¨ `raw_dsc` ä¸Š
- âš ï¸ CSV æ—¥å¿—ä»ä¿ç•™æ‰€æœ‰æŒ‡æ ‡ï¼ˆä¾¿äºåç»­åˆ†æï¼‰

---

## ğŸ”§ ç¬¬äºŒéƒ¨åˆ†ï¼šé•¿æœŸä¿®å¤ï¼ˆå¾…å®ç°ï¼‰

### æ ¸å¿ƒç›®æ ‡

å®ç°è®ºæ–‡æè¿°çš„å®Œæ•´åå¤„ç†æµç¨‹ï¼š
1. åœ¨ä½åˆ†è¾¨ç‡ç½‘æ ¼ï¼ˆN â‰ˆ 9000ï¼‰ä¸Šè¿›è¡Œæ¨¡å‹é¢„æµ‹
2. åº”ç”¨ Graph-cut å¹³æ»‘ï¼ˆåœ¨ä½åˆ†è¾¨ç‡ä¸Šï¼‰
3. **ä½¿ç”¨ SVM ä¸Šé‡‡æ ·åˆ°åŸå§‹é«˜åˆ†è¾¨ç‡ç½‘æ ¼ï¼ˆN â‰ˆ 100kï¼‰**
4. åœ¨é«˜åˆ†è¾¨ç‡ç½‘æ ¼ä¸Šè®¡ç®—æœ€ç»ˆçš„ `post_*` æŒ‡æ ‡

---

### å®ç°è·¯çº¿å›¾

#### æ­¥éª¤1ï¼šä¿®æ”¹æ•°æ®åŠ è½½å™¨ï¼Œä¼ é€’åŸå§‹æ–‡ä»¶è·¯å¾„

**æ–‡ä»¶**: `m0_dataset.py`

**ä¿®æ”¹ SegmentationDataset.__getitem__**:

```python
def __getitem__(self, idx: int) -> Tuple[Tuple[torch.Tensor, ...], torch.Tensor, str]:
    base_idx, variant_idx = self._resolve_index(idx)
    file_path = Path(self.file_paths[base_idx])
    
    # ... ç°æœ‰çš„æ•°æ®åŠ è½½å’Œå¤„ç†é€»è¾‘ ...
    
    # è¿”å›æ—¶æ·»åŠ åŸå§‹æ–‡ä»¶è·¯å¾„
    return (x, pos_norm, pos_mm_scaled, pos_scale), y_tensor, str(file_path)
```

**ä¿®æ”¹ segmentation_collate**:

```python
def segmentation_collate(batch):
    batch_data, ys, filepaths = zip(*batch)
    xs, pos_norms, pos_mms, pos_scales = zip(*batch_data)
    x = torch.stack(xs, dim=0)
    pos_norm = torch.stack(pos_norms, dim=0)
    pos_mm = torch.stack(pos_mms, dim=0)
    pos_scale = torch.stack(pos_scales, dim=0)
    y = torch.stack(ys, dim=0)
    return (x, pos_norm, pos_mm, pos_scale), y, list(filepaths)
```

---

#### æ­¥éª¤2ï¼šä¿®æ”¹è®­ç»ƒå™¨çš„éªŒè¯å¾ªç¯

**æ–‡ä»¶**: `m1_train.py`

**ä¿®æ”¹ Trainer._run_epoch**:

```python
def _run_epoch(self, loader: DataLoader, is_train: bool):
    # ...
    for batch_data in tqdm(loader, desc=desc):
        if len(batch_data) == 3:  # æ–°æ ¼å¼ï¼šåŒ…å«æ–‡ä»¶è·¯å¾„
            (x, pos_norm, pos_mm, pos_scale), y, filepaths = batch_data
        else:  # å…¼å®¹æ—§æ ¼å¼
            (x, pos_norm, pos_mm, pos_scale), y = batch_data
            filepaths = [None] * x.size(0)
        
        # ... è®­ç»ƒ/éªŒè¯é€»è¾‘ ...
        
        if not is_train:
            # ... æ”¶é›†é¢„æµ‹ç»“æœ ...
            for i in range(preds.size(0)):
                case_records.append({
                    "prob": probs[i].transpose(0, 1).contiguous().numpy(),
                    "pred": preds[i].numpy(),
                    "target": targets_cpu[i].numpy(),
                    "pos_mm": pos_mm_cpu[i].numpy(),
                    "diag": float(pos_scale_cpu[i].item()),
                    "filepath": filepaths[i],  # æ–°å¢ï¼šåŸå§‹æ–‡ä»¶è·¯å¾„
                })
```

---

#### æ­¥éª¤3ï¼šå®ç°æ–°çš„è¯„ä¼°å‡½æ•°ï¼ˆæ”¯æŒé«˜åˆ†è¾¨ç‡ä¸Šé‡‡æ ·ï¼‰

**æ–‡ä»¶**: `m1_train.py`

**æ–°å¢å‡½æ•° evaluate_cases_with_upsampling**:

```python
def evaluate_cases_with_upsampling(
    cases: List[Dict[str, any]], 
    num_classes: int
) -> Tuple[Dict[str, Dict[str, float]], Dict[str, Dict[str, float]]]:
    """
    å®Œæ•´å®ç°è®ºæ–‡çš„åå¤„ç†è¯„ä¼°æµç¨‹ï¼š
    1. Raw metrics: åœ¨ä½åˆ†è¾¨ç‡ç½‘æ ¼ä¸Šç›´æ¥è¯„ä¼°
    2. Post metrics: Graph-cut (ä½åˆ†è¾¨ç‡) + SVMä¸Šé‡‡æ ·åˆ°é«˜åˆ†è¾¨ç‡ + é«˜åˆ†è¾¨ç‡è¯„ä¼°
    """
    from m0_dataset import find_label_array, remap_segmentation_labels
    import pyvista as pv
    
    raw_metrics: List[Dict[str, float]] = []
    post_metrics: List[Dict[str, float]] = []
    
    for case in tqdm(cases, desc="Evaluating with upsampling"):
        # ===== 1. Raw Metricsï¼ˆä½åˆ†è¾¨ç‡ç›´æ¥é¢„æµ‹ï¼‰=====
        raw_metrics.append(
            compute_case_metrics(
                pred_labels=case["pred"],
                target_labels=case["target"],
                pos_mm=case["pos_mm"],
                num_classes=num_classes,
                fallback_diag=case["diag"]
            )
        )
        
        # ===== 2. Post Metricsï¼ˆå®Œæ•´åå¤„ç†æµç¨‹ï¼‰=====
        if case["filepath"] is None:
            # å¦‚æœæ²¡æœ‰æ–‡ä»¶è·¯å¾„ï¼Œå›é€€åˆ°æ—§æ–¹æ³•
            post_pred = apply_post_processing(case["prob"], case["pos_mm"])
            post_metrics.append(
                compute_case_metrics(
                    pred_labels=post_pred,
                    target_labels=case["target"],
                    pos_mm=case["pos_mm"],
                    num_classes=num_classes,
                    fallback_diag=case["diag"]
                )
            )
            continue
        
        # 2.1 åœ¨ä½åˆ†è¾¨ç‡ä¸Šåº”ç”¨ Graph-cut
        low_res_probs = case["prob"]  # (N_low, C), N_low â‰ˆ 9000
        low_res_pos_mm = case["pos_mm"]  # (N_low, 3)
        
        refined_low_res_probs = graphcut_refine(
            low_res_probs, 
            low_res_pos_mm, 
            beta=30.0, 
            k=6, 
            iterations=1
        )
        low_res_pred_labels = np.argmax(refined_low_res_probs, axis=1)
        
        # 2.2 åŠ è½½åŸå§‹é«˜åˆ†è¾¨ç‡ç½‘æ ¼
        try:
            high_res_mesh = pv.read(case["filepath"])
            
            # æå–é«˜åˆ†è¾¨ç‡çš„çœŸå®æ ‡ç­¾
            label_result = find_label_array(high_res_mesh)
            if label_result is None:
                raise ValueError(f"No labels found in {case['filepath']}")
            
            _, high_res_true_labels_raw = label_result
            high_res_true_labels = remap_segmentation_labels(
                np.asarray(high_res_true_labels_raw)
            )
            
            # è·å–é«˜åˆ†è¾¨ç‡çš„å•å…ƒä¸­å¿ƒç‚¹åæ ‡
            high_res_mesh.compute_normals(cell_normals=True, inplace=True)
            high_res_pos_mm = high_res_mesh.cell_centers().points  # (N_high, 3), N_high â‰ˆ 100k
            
        except Exception as e:
            print(f"Warning: Failed to load high-res mesh from {case['filepath']}: {e}")
            # å›é€€åˆ°ä½åˆ†è¾¨ç‡è¯„ä¼°
            post_metrics.append(
                compute_case_metrics(
                    pred_labels=low_res_pred_labels,
                    target_labels=case["target"],
                    pos_mm=case["pos_mm"],
                    num_classes=num_classes,
                    fallback_diag=case["diag"]
                )
            )
            continue
        
        # 2.3 ä½¿ç”¨ SVM ä»ä½åˆ†è¾¨ç‡ä¸Šé‡‡æ ·åˆ°é«˜åˆ†è¾¨ç‡
        try:
            # è®­ç»ƒ SVMï¼ˆåœ¨ä½åˆ†è¾¨ç‡é¢„æµ‹ç»“æœä¸Šï¼‰
            unique_labels = np.unique(low_res_pred_labels)
            if unique_labels.size <= 1:
                # å¦‚æœåªæœ‰ä¸€ä¸ªç±»åˆ«ï¼Œç›´æ¥ç”¨è¯¥ç±»åˆ«å¡«å……
                high_res_pred_labels = np.full(high_res_pos_mm.shape[0], unique_labels[0])
            else:
                # é™åˆ¶è®­ç»ƒæ ·æœ¬æ•°é‡ä»¥åŠ é€Ÿ
                max_train_samples = 5000
                if low_res_pos_mm.shape[0] > max_train_samples:
                    train_indices = np.random.choice(
                        low_res_pos_mm.shape[0], 
                        size=max_train_samples, 
                        replace=False
                    )
                    train_x = low_res_pos_mm[train_indices]
                    train_y = low_res_pred_labels[train_indices]
                else:
                    train_x = low_res_pos_mm
                    train_y = low_res_pred_labels
                
                # è®­ç»ƒ SVM
                svm = SVC(kernel="rbf", C=1.0, gamma="scale", decision_function_shape="ovr")
                svm.fit(train_x.astype(np.float64), train_y)
                
                # é¢„æµ‹é«˜åˆ†è¾¨ç‡æ ‡ç­¾
                high_res_pred_labels = svm.predict(high_res_pos_mm.astype(np.float64))
            
            # 2.4 åœ¨é«˜åˆ†è¾¨ç‡ä¸Šè®¡ç®— post æŒ‡æ ‡
            high_res_diag = compute_diag_from_points(high_res_pos_mm)
            post_metrics.append(
                compute_case_metrics(
                    pred_labels=high_res_pred_labels,
                    target_labels=high_res_true_labels,
                    pos_mm=high_res_pos_mm,
                    num_classes=num_classes,
                    fallback_diag=high_res_diag
                )
            )
            
        except Exception as e:
            print(f"Warning: SVM upsampling failed for {case['filepath']}: {e}")
            # å›é€€åˆ°ä½åˆ†è¾¨ç‡è¯„ä¼°
            post_metrics.append(
                compute_case_metrics(
                    pred_labels=low_res_pred_labels,
                    target_labels=case["target"],
                    pos_mm=case["pos_mm"],
                    num_classes=num_classes,
                    fallback_diag=case["diag"]
                )
            )
    
    return summarize_metrics(raw_metrics), summarize_metrics(post_metrics)
```

---

#### æ­¥éª¤4ï¼šä¿®æ”¹è®­ç»ƒå™¨ä½¿ç”¨æ–°çš„è¯„ä¼°å‡½æ•°

**æ–‡ä»¶**: `m1_train.py`

**ä¿®æ”¹ Trainer._run_epoch**:

```python
def _run_epoch(self, loader: DataLoader, is_train: bool):
    # ...
    
    avg_loss = total_loss / max(len(loader), 1)
    if not is_train:
        # ä½¿ç”¨æ–°çš„è¯„ä¼°å‡½æ•°ï¼ˆæ”¯æŒé«˜åˆ†è¾¨ç‡ä¸Šé‡‡æ ·ï¼‰
        raw_metrics, post_metrics = evaluate_cases_with_upsampling(
            case_records, 
            self.config.num_classes
        )
        return avg_loss, raw_metrics, post_metrics
    return avg_loss, None, None
```

---

### å®ç°åçš„æ•ˆæœ

å®Œæˆé•¿æœŸä¿®å¤åï¼š

1. âœ… **Raw Metrics**: åœ¨ä½åˆ†è¾¨ç‡ç½‘æ ¼ä¸Šè¯„ä¼°ï¼ˆN â‰ˆ 9000ï¼‰
   - åæ˜ æ¨¡å‹åœ¨ä¸‹é‡‡æ ·ç½‘æ ¼ä¸Šçš„ç›´æ¥æ€§èƒ½

2. âœ… **Post Metrics**: åœ¨åŸå§‹é«˜åˆ†è¾¨ç‡ç½‘æ ¼ä¸Šè¯„ä¼°ï¼ˆN â‰ˆ 100kï¼‰
   - Graph-cut å¹³æ»‘ï¼ˆä½åˆ†è¾¨ç‡ï¼‰
   - SVM ä¸Šé‡‡æ ·åˆ°é«˜åˆ†è¾¨ç‡
   - åœ¨é«˜åˆ†è¾¨ç‡ä¸Šè®¡ç®—æœ€ç»ˆæŒ‡æ ‡
   - **ä¸è®ºæ–‡æ–¹æ³•å®Œå…¨ä¸€è‡´**

3. âœ… **å¯æ¯”æ€§**: Post metrics å¯ä»¥ä¸è®ºæ–‡ç»“æœç›´æ¥æ¯”è¾ƒ

---

## ğŸ“Š å½“å‰çŠ¶æ€æ€»ç»“

### å·²å®Œæˆ âœ…

- [x] ä¸º `graphcut_refine` æ·»åŠ è­¦å‘Šæ³¨é‡Š
- [x] ä¸º `svm_refine` æ·»åŠ è­¦å‘Šæ³¨é‡Š
- [x] æ³¨é‡Šæ‰æ‰“å°è¾“å‡ºä¸­çš„æ— æ•ˆ `post_*` æŒ‡æ ‡
- [x] ç¡®è®¤æ¨¡å‹ä¿å­˜é€»è¾‘æ­£ç¡®ä½¿ç”¨ `raw_dsc`
- [x] åˆ›å»ºå®Œæ•´çš„é•¿æœŸä¿®å¤å®ç°è®¡åˆ’

### å¾…å®Œæˆ â³

- [ ] ä¿®æ”¹ `m0_dataset.py` ä¼ é€’æ–‡ä»¶è·¯å¾„
- [ ] ä¿®æ”¹ `segmentation_collate` å‡½æ•°
- [ ] ä¿®æ”¹ `Trainer._run_epoch` æ”¶é›†æ–‡ä»¶è·¯å¾„
- [ ] å®ç° `evaluate_cases_with_upsampling` å‡½æ•°
- [ ] æµ‹è¯•å®Œæ•´çš„ä¸Šé‡‡æ ·è¯„ä¼°æµç¨‹

---

## ğŸ¯ è®­ç»ƒå»ºè®®

### å½“å‰é˜¶æ®µï¼ˆçŸ­æœŸä¿®å¤åï¼‰

1. **å…³æ³¨æŒ‡æ ‡**: åªçœ‹ `raw_*` æŒ‡æ ‡
   - `raw_dsc`: Dice ç³»æ•°ï¼ˆæœ€é‡è¦ï¼‰
   - `raw_sen`: æ•æ„Ÿåº¦/å¬å›ç‡
   - `raw_ppv`: ç²¾ç¡®åº¦
   - `raw_hd`: Hausdorff è·ç¦»

2. **å¿½ç•¥æŒ‡æ ‡**: å®Œå…¨å¿½ç•¥ `post_*` æŒ‡æ ‡
   - è¿™äº›æŒ‡æ ‡åœ¨å½“å‰å®ç°ä¸­æ˜¯æ— æ•ˆçš„

3. **æ¨¡å‹é€‰æ‹©**: æ ¹æ® `raw_dsc` é€‰æ‹©æœ€ä½³æ¨¡å‹
   - è®­ç»ƒå™¨å·²æ­£ç¡®é…ç½®ä¸ºä¿å­˜ `raw_dsc` æœ€é«˜çš„æ¨¡å‹

### é•¿æœŸä¿®å¤å

å®Œæˆä¸Šé‡‡æ ·è¯„ä¼°åï¼š
- `raw_*` æŒ‡æ ‡: ä½åˆ†è¾¨ç‡æ€§èƒ½å‚è€ƒ
- `post_*` æŒ‡æ ‡: é«˜åˆ†è¾¨ç‡æœ€ç»ˆæ€§èƒ½ï¼ˆå¯ä¸è®ºæ–‡æ¯”è¾ƒï¼‰

---

## ğŸ“ å‚è€ƒ

**è®ºæ–‡æ–¹æ³•** (æ­£ç¡®çš„åå¤„ç†æµç¨‹):
1. æ¨¡å‹åœ¨ä½åˆ†è¾¨ç‡ç½‘æ ¼é¢„æµ‹ (N â‰ˆ 9k)
2. Graph-cut å¹³æ»‘ (ä½åˆ†è¾¨ç‡)
3. **SVM ä¸Šé‡‡æ ·åˆ°åŸå§‹é«˜åˆ†è¾¨ç‡** (N â‰ˆ 100k)
4. åœ¨é«˜åˆ†è¾¨ç‡ä¸Šè¯„ä¼°æœ€ç»ˆæŒ‡æ ‡

**å½“å‰å®ç°** (çŸ­æœŸä¿®å¤å):
1. æ¨¡å‹åœ¨ä½åˆ†è¾¨ç‡ç½‘æ ¼é¢„æµ‹ (N â‰ˆ 9k)
2. ~~Graph-cut å¹³æ»‘~~ (k-NN æ¦‚ç‡å¹³æ»‘)
3. ~~SVM åœ¨ä½åˆ†è¾¨ç‡ä¸Šç»†åŒ–~~ (æ— ä¸Šé‡‡æ ·)
4. âœ… åœ¨ä½åˆ†è¾¨ç‡ä¸Šè¯„ä¼° `raw_*` æŒ‡æ ‡ï¼ˆæœ‰æ•ˆï¼‰
5. âŒ `post_*` æŒ‡æ ‡æ— æ•ˆï¼ˆå·²æ³¨é‡Šï¼‰

---

**åˆ›å»ºæ—¥æœŸ**: 2025-10-02
**æœ€åæ›´æ–°**: 2025-10-02
**çŠ¶æ€**: çŸ­æœŸä¿®å¤å·²å®Œæˆï¼Œé•¿æœŸä¿®å¤å¾…å®ç°
