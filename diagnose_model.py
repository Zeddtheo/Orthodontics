"""
è¯Šæ–­è„šæœ¬ï¼šå¯¹è®­ç»ƒæ ·æœ¬è¿›è¡Œæ¨ç†ï¼ŒéªŒè¯æ¨¡å‹æ˜¯å¦çœŸçš„å­¦åˆ°äº†
"""
import torch
import numpy as np
import pyvista as pv
from pathlib import Path
import sys

sys.path.insert(0, 'src/iMeshSegNet')
from imeshsegnet import iMeshSegNet
from m0_dataset import extract_features, normalize_mesh_units, load_stats, remap_segmentation_labels

# 1. åŠ è½½æ¨¡å‹
device = torch.device('cpu')
model = iMeshSegNet(num_classes=15).to(device)
ckpt = torch.load('outputs/overfit/best_model.pth', map_location='cpu', weights_only=False)
model.load_state_dict(ckpt['model_state_dict'])
model.eval()
print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (Epoch {ckpt['epoch']}, DSC={ckpt['val_dsc']:.4f})")

# 2. åŠ è½½è®­ç»ƒæ ·æœ¬
mesh = pv.read('datasets/segmentation_dataset/1_U.vtp')
mesh.points -= mesh.center
mesh, scale_factor, diag_before, diag_after = normalize_mesh_units(mesh)
mesh = mesh.triangulate()

# 3. å…ˆæå–çœŸå®æ ‡ç­¾ï¼ˆåœ¨æŠ½å–å‰ï¼‰
true_labels_raw = remap_segmentation_labels(np.asarray(mesh.cell_data['Label']))

# 4. æŠ½å–åˆ° 10000 cells (ä¸æ¨ç†ä¸€è‡´)
if mesh.n_cells > 10000:
    reduction = 1.0 - (10000 / float(mesh.n_cells))
    mesh_decimated = mesh.decimate_pro(reduction, feature_angle=45, preserve_topology=True)
else:
    mesh_decimated = mesh
print(f"âœ… ç½‘æ ¼æŠ½å–: {mesh_decimated.n_cells} cells")

# 5. é‡‡æ ·åˆ° 6000 cells
N = mesh_decimated.n_cells
if N > 6000:
    ids = np.random.permutation(N)[:6000]
    submesh = mesh_decimated.extract_cells(ids.astype(np.int32)).clean()
    submesh = submesh.cast_to_unstructured_grid().extract_surface()
    # ç”±äºæŠ½å–å’Œé‡‡æ ·ä¼šæ”¹å˜ cell çš„å¯¹åº”å…³ç³»ï¼Œæˆ‘ä»¬åªèƒ½ç”¨é‡‡æ ·åçš„ç½‘æ ¼
    # æ— æ³•ç²¾ç¡®è·å–çœŸå®æ ‡ç­¾ï¼Œæ‰€ä»¥åªèƒ½è¯„ä¼°å¤§è‡´çš„æ€§èƒ½
    true_labels = np.zeros(submesh.n_cells, dtype=np.int64)  # å ä½ç¬¦
    has_true_labels = False
else:
    submesh = mesh_decimated
    true_labels = np.zeros(submesh.n_cells, dtype=np.int64)
    has_true_labels = False

print(f"âœ… é‡‡æ ·: {submesh.n_cells} cells")

# 5. æå–ç‰¹å¾
feats = extract_features(submesh).astype(np.float32)
pos_raw = submesh.cell_centers().points.astype(np.float32)
scale_pos = diag_after if diag_after > 1e-6 else 1.0
pos_raw = pos_raw / scale_pos

# 6. æ ‡å‡†åŒ–
mean, std = load_stats(Path('outputs/segmentation/stats.npz'))
feats_t = torch.from_numpy(feats)
feats_t = (feats_t - torch.from_numpy(mean)) / torch.from_numpy(std)
feats_t = feats_t.transpose(0, 1).contiguous().unsqueeze(0)  # (1,15,N)

pos_t = torch.from_numpy(pos_raw).transpose(0, 1).contiguous().unsqueeze(0)  # (1,3,N)

feats_t = feats_t.to(device).float()
pos_t = pos_t.to(device).float()

# 7. æ¨ç†
with torch.no_grad():
    logits = model(feats_t, pos_t)  # (1,15,N)
    pred = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy()  # (N,)

# 8. åªåˆ†æé¢„æµ‹åˆ†å¸ƒï¼ˆæ— æ³•ç²¾ç¡®è®¡ç®—å‡†ç¡®ç‡ï¼Œå› ä¸ºæŠ½å–/é‡‡æ ·æ”¹å˜äº† cell å¯¹åº”å…³ç³»ï¼‰
print(f"\nğŸ“Š æ¨ç†ç»“æœ:")
unique_pred, counts_pred = np.unique(pred, return_counts=True)
print("  é¢„æµ‹æ ‡ç­¾åˆ†å¸ƒ:")
for u, c in zip(unique_pred, counts_pred):
    print(f"    L{u}: {c} cells ({c/len(pred)*100:.1f}%)")

# 9. å¯¹æ¯”åŸå§‹è®­ç»ƒæ•°æ®çš„æ ‡ç­¾åˆ†å¸ƒ
print(f"\nğŸ“ˆ åŸå§‹è®­ç»ƒæ•°æ® (1_U.vtp) æ ‡ç­¾åˆ†å¸ƒ:")
unique_true, counts_true = np.unique(true_labels_raw, return_counts=True)
for u, c in zip(unique_true, counts_true):
    print(f"    L{u}: {c} cells ({c/len(true_labels_raw)*100:.1f}%)")

# 10. æ£€æŸ¥å“ªäº›ç±»åˆ«è¢«é—æ¼
missing = set(unique_true) - set(unique_pred)
if missing:
    print(f"\nâŒ æ¨¡å‹é—æ¼äº†è¿™äº›ç±»åˆ«: {sorted(missing)}")
    print("   è¿™è¡¨æ˜æ¨¡å‹è¿‡æ‹Ÿåˆæ²¡æœ‰æˆåŠŸå­¦åˆ°æ‰€æœ‰ç±»åˆ«ï¼")
else:
    print("\nâœ… æ¨¡å‹è¾“å‡ºäº†æ‰€æœ‰è®­ç»ƒç±»åˆ«")
