# Linux å…¼å®¹æ€§ä¿®å¤æ€»ç»“

## ä¿®æ”¹å†…å®¹

### 1. AMP (Automatic Mixed Precision) å…¼å®¹æ€§ä¿®å¤

#### é—®é¢˜æè¿°
åŸå§‹ä»£ç ä½¿ç”¨ `torch.cuda.amp`ï¼Œåœ¨ä»¥ä¸‹æƒ…å†µä¼šå¤±è´¥ï¼š
- CPU-only PyTorch ç¯å¢ƒï¼ˆæ—  CUDA æ”¯æŒï¼‰
- æ—§ç‰ˆ PyTorch (< 1.10) åœ¨ Linux ä¸Šçš„ä¸€äº›æ„å»º
- æŸäº›æœåŠ¡å™¨ç¯å¢ƒçš„ PyTorch ç²¾ç®€ç‰ˆ

#### ä¿®å¤æ–¹æ¡ˆ
å®ç°äº†ä¸‰å±‚ fallback æœºåˆ¶ï¼š

```python
# ç¬¬1å±‚ï¼šå°è¯•torch.amp (PyTorch >= 1.10, æ¨è)
try:
    from torch.amp import autocast, GradScaler
    HAS_AMP = True
except ImportError:
    # ç¬¬2å±‚ï¼šå°è¯• torch.cuda.amp (PyTorch < 1.10)
    try:
        from torch.cuda.amp import autocast, GradScaler
        HAS_AMP = True
    except ImportError:
        # ç¬¬3å±‚ï¼šCPU fallback - æä¾› dummy å®ç°
        HAS_AMP = False
        class GradScaler:
            def __init__(self, enabled=False): ...
            def scale(self, loss): return loss
            def step(self, optimizer): optimizer.step()
            def update(self): pass
            def unscale_(self, optimizer): pass
        autocast = nullcontext
```

### 2. GradScaler åˆå§‹åŒ–å…¼å®¹æ€§

#### é—®é¢˜æè¿°
- PyTorch >= 2.0: `GradScaler(device='cuda', enabled=True)`
- PyTorch < 2.0: `GradScaler(enabled=True)` (æ—  device å‚æ•°)

#### ä¿®å¤æ–¹æ¡ˆ
```python
if HAS_AMP:
    try:
        # æ–°ç‰ˆ API: å°è¯•ä½¿ç”¨ device å‚æ•°
        self.scaler = GradScaler(device=self.device_type, enabled=self.amp_enabled)
    except TypeError:
        # æ—§ç‰ˆ API: å›é€€åˆ°æ—  device å‚æ•°
        self.scaler = GradScaler(enabled=self.amp_enabled)
else:
    # CPU fallback
    self.scaler = GradScaler(enabled=False)
```

### 3. autocast ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¼å®¹æ€§

#### é—®é¢˜æè¿°
- PyTorch >= 1.10: `autocast(device_type='cuda', enabled=True)`
- PyTorch < 1.10: `autocast(enabled=True)`
- CPUæ¨¡å¼: ä¸åº”ä½¿ç”¨ autocast

#### ä¿®å¤æ–¹æ¡ˆ
```python
if self.amp_enabled and HAS_AMP:
    try:
        # æ–°ç‰ˆ API
        autocast_ctx = autocast(device_type=self.device_type, enabled=True)
    except TypeError:
        # æ—§ç‰ˆ API
        autocast_ctx = autocast(enabled=True)
else:
    # CPU æˆ–æ—  AMP: ä½¿ç”¨ nullcontext (æ— æ“ä½œ)
    autocast_ctx = nullcontext()

with autocast_ctx:
    logits = self.model(x, pos_norm)
    loss = self.dice_loss(logits, y)
```

## æµ‹è¯•å…¼å®¹æ€§

è¿è¡Œæµ‹è¯•è„šæœ¬æ£€æŸ¥ç¯å¢ƒï¼š
```bash
python test_amp_compatibility.py
```

### é¢„æœŸè¾“å‡º

#### GPU ç¯å¢ƒ (CUDA å¯ç”¨)
```
âœ… torch.amp.autocast å¯ç”¨ (PyTorch >= 1.10)
âœ… GradScaler(device='cuda') åˆå§‹åŒ–æˆåŠŸ
âœ… autocast(device_type='cuda') å·¥ä½œæ­£å¸¸
ğŸ¯ GPU + AMP æ¨¡å¼ï¼šæ··åˆç²¾åº¦è®­ç»ƒå·²å¯ç”¨
```

#### CPU ç¯å¢ƒ
```
âœ… torch.amp.autocast å¯ç”¨
âœ… GradScaler(device='cpu') åˆå§‹åŒ–æˆåŠŸ
ğŸ“Š Scaler enabled: False
â„¹ï¸  CPU æ¨¡å¼ï¼šGradScaler ä¼šè¢«ç¦ç”¨ï¼Œautocast ä¼šè¢«è·³è¿‡
```

#### æ—§ç‰ˆ PyTorch ç¯å¢ƒ
```
âœ… torch.cuda.amp.autocast å¯ç”¨ (PyTorch < 1.10)
âœ… GradScaler(enabled=True) åˆå§‹åŒ–æˆåŠŸ (æ—§ç‰ˆ API)
```

## å…¼å®¹æ€§ä¿è¯

### æ”¯æŒçš„ç¯å¢ƒ
âœ… PyTorch 2.x + CUDA (æ¨èé…ç½®)
âœ… PyTorch 2.x + CPU  
âœ… PyTorch 1.10+ + CUDA
âœ… PyTorch 1.10+ + CPU
âœ… PyTorch < 1.10 + CUDA
âœ… PyTorch < 1.10 + CPU (æœ‰é™æ”¯æŒ)

### ç‰¹æ€§å¯¹ç…§è¡¨

| ç¯å¢ƒ | AMP | æ··åˆç²¾åº¦ | è®­ç»ƒé€Ÿåº¦ |
|------|-----|----------|----------|
| PyTorch 2.x + CUDA | âœ… | âœ… FP16 | 1.5-3x åŠ é€Ÿ |
| PyTorch 2.x + CPU | âœ… | âŒ FP32 | åŸºå‡†é€Ÿåº¦ |
| PyTorch 1.x + CUDA | âœ… | âœ… FP16 | 1.5-3x åŠ é€Ÿ |
| PyTorch 1.x + CPU | âš ï¸ | âŒ FP32 | åŸºå‡†é€Ÿåº¦ |

### è¡Œä¸ºè¯´æ˜

#### CUDA ç¯å¢ƒ
- `amp_enabled = True`: å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
- GradScaler æ¿€æ´»ï¼Œè‡ªåŠ¨ç¼©æ”¾æ¢¯åº¦é˜²æ­¢ä¸‹æº¢
- autocast è‡ªåŠ¨å°†éƒ¨åˆ†æ“ä½œè½¬æ¢ä¸º FP16
- æ˜¾å­˜å ç”¨å‡å°‘çº¦ 40%
- è®­ç»ƒé€Ÿåº¦æå‡ 1.5-3x

#### CPU ç¯å¢ƒ
- `amp_enabled = False`: ç¦ç”¨æ··åˆç²¾åº¦
- GradScaler ç©ºæ“ä½œ (ç›´æ¥è°ƒç”¨ optimizer.step())
- autocast ä½¿ç”¨ nullcontext (æ— æ“ä½œ)
- æ‰€æœ‰è®¡ç®—ä½¿ç”¨ FP32
- å…¼å®¹æ€§æœ€ä½³ï¼Œä½†é€Ÿåº¦è¾ƒæ…¢

## æ½œåœ¨é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### é—®é¢˜ 1: å¯¼å…¥é”™è¯¯ "No module named 'torch.amp'"
**åŸå› **: PyTorch ç‰ˆæœ¬ < 1.10 æˆ– CPU-only æ„å»º  
**è§£å†³**: ä»£ç ä¼šè‡ªåŠ¨å›é€€åˆ° `torch.cuda.amp` æˆ– CPU fallback

### é—®é¢˜ 2: TypeError: __init__() got an unexpected keyword argument 'device'
**åŸå› **: PyTorch ç‰ˆæœ¬ < 2.0  
**è§£å†³**: try-except ä¼šæ•è·å¹¶ä½¿ç”¨æ—§ç‰ˆ API

### é—®é¢˜ 3: è®­ç»ƒåœ¨ CPU ä¸Šå¾ˆæ…¢
**åŸå› **: CPU ä¸æ”¯æŒæ··åˆç²¾åº¦ï¼Œå…¨éƒ¨ä½¿ç”¨ FP32  
**è§£å†³**: è¿™æ˜¯é¢„æœŸè¡Œä¸ºï¼Œå»ºè®®ä½¿ç”¨ GPU æˆ–å‡å°‘æ¨¡å‹å¤§å°

### é—®é¢˜ 4: CUDA out of memory
**åŸå› **: å³ä½¿ä½¿ç”¨ AMPï¼Œæ¨¡å‹ä»å¯èƒ½å¤ªå¤§  
**è§£å†³**: 
- å‡å° batch_size
- å‡å° sample_cells (9000 â†’ 6000)
- ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯

## éªŒè¯æ¸…å•

åœ¨ Linux æœåŠ¡å™¨ä¸Šéƒ¨ç½²å‰ï¼Œè¯·ç¡®è®¤ï¼š

- [ ] è¿è¡Œ `test_amp_compatibility.py` æ— é”™è¯¯
- [ ] æ£€æŸ¥ PyTorch ç‰ˆæœ¬: `python -c "import torch; print(torch.__version__)"`
- [ ] æ£€æŸ¥ CUDA å¯ç”¨æ€§: `python -c "import torch; print(torch.cuda.is_available())"`
- [ ] æµ‹è¯•è®­ç»ƒè„šæœ¬: `python src/iMeshSegNet/m1_train.py` (è‡³å°‘è¿è¡Œ 1 epoch)
- [ ] ç›‘æ§æ˜¾å­˜ä½¿ç”¨: `nvidia-smi` (GPUç¯å¢ƒ)
- [ ] æ£€æŸ¥è®­ç»ƒæ—¥å¿—æ˜¯å¦æ­£å¸¸è¾“å‡º

## ä¿®æ”¹æ–‡ä»¶

### ä¸»è¦ä¿®æ”¹
- `src/iMeshSegNet/m1_train.py`: AMP å…¼å®¹æ€§ä¿®å¤

### æ–°å¢æ–‡ä»¶
- `test_amp_compatibility.py`: AMP å…¼å®¹æ€§æµ‹è¯•è„šæœ¬
- `LINUX_COMPATIBILITY.md`: æœ¬æ–‡æ¡£

## æ€§èƒ½å½±å“

### ä¿®æ”¹å‰
- âŒ ä»…æ”¯æŒ CUDA ç¯å¢ƒ
- âŒ åœ¨ CPU ç¯å¢ƒä¼šå´©æºƒ
- âŒ ä¸å…¼å®¹æ—§ç‰ˆ PyTorch

### ä¿®æ”¹å
- âœ… æ”¯æŒ CUDA å’Œ CPU
- âœ… è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨æœ€ä½³ API
- âœ… å…¼å®¹ PyTorch 1.x å’Œ 2.x
- âœ… æ€§èƒ½æ— æŸå¤±ï¼ˆGPU ç¯å¢ƒï¼‰
- âœ… CPU ç¯å¢ƒå¯æ­£å¸¸è¿è¡Œï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰

## å‚è€ƒèµ„æ–™

- [PyTorch AMP æ–‡æ¡£](https://pytorch.org/docs/stable/amp.html)
- [torch.cuda.amp vs torch.amp è¿ç§»æŒ‡å—](https://pytorch.org/docs/stable/notes/amp_examples.html)
- [GradScaler API å‚è€ƒ](https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.GradScaler)
