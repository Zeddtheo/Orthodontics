#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®æ”¹åçš„p0_dataset.pyæ–°åŠŸèƒ½
"""

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))

from p0_dataset import DatasetConfig, P0PointNetRegDataset, make_dataloader
from tooth_groups import TOOTH_GROUPS, get_group_teeth

def test_group_filtering():
    """æµ‹è¯•åˆ†ç»„ç­›é€‰åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•åˆ†ç»„ç­›é€‰åŠŸèƒ½")
    
    # æµ‹è¯•æŒ‰ç»„ç­›é€‰
    cfg = DatasetConfig(
        root="../../datasets/landmarks_dataset/cooked/p0/samples_consistent",
        group="m1",  # æµ‹è¯•ç¬¬ä¸€ç£¨ç‰™ç»„
        features="all",
        select_landmarks="active",
        ensure_constant_L=True
    )
    
    try:
        dataset = P0PointNetRegDataset(cfg)
        print(f"âœ… ç»„ç­›é€‰æˆåŠŸ: æ‰¾åˆ° {len(dataset)} ä¸ª m1 ç»„æ ·æœ¬")
        print(f"   ç»„å†…ç‰™ä½: {get_group_teeth('m1')}")
        
        # æµ‹è¯•æ ·æœ¬
        sample = dataset[0]
        print(f"   æ ·æœ¬å½¢çŠ¶: x={sample['x'].shape}, y={sample['y'].shape}")
        print(f"   å…ƒä¿¡æ¯: tooth_id={sample['meta'].get('tooth_id')}, group={sample['meta'].get('group')}")
        
    except Exception as e:
        print(f"âŒ ç»„ç­›é€‰æµ‹è¯•å¤±è´¥: {e}")

def test_tooth_ids_filtering():
    """æµ‹è¯•æ˜¾å¼ç‰™ä½åˆ—è¡¨ç­›é€‰"""
    print("\nğŸ§ª æµ‹è¯•æ˜¾å¼ç‰™ä½åˆ—è¡¨ç­›é€‰")
    
    cfg = DatasetConfig(
        root="../../datasets/landmarks_dataset/cooked/p0/samples_consistent",
        tooth_ids=["t31", "t32"],  # æµ‹è¯•æŒ‡å®šç‰™ä½
        features="all",
        select_landmarks="active",
        ensure_constant_L=True
    )
    
    try:
        dataset = P0PointNetRegDataset(cfg)
        print(f"âœ… ç‰™ä½ç­›é€‰æˆåŠŸ: æ‰¾åˆ° {len(dataset)} ä¸ª t31+t32 æ ·æœ¬")
        
        # æ£€æŸ¥å‰å‡ ä¸ªæ ·æœ¬çš„ç‰™ä½
        tooth_counts = {}
        for i in range(min(10, len(dataset))):
            sample = dataset[i]
            tooth_id = sample['meta'].get('tooth_id', 'unknown')
            tooth_counts[tooth_id] = tooth_counts.get(tooth_id, 0) + 1
        
        print(f"   å‰10ä¸ªæ ·æœ¬ç‰™ä½åˆ†å¸ƒ: {tooth_counts}")
        
    except Exception as e:
        print(f"âŒ ç‰™ä½ç­›é€‰æµ‹è¯•å¤±è´¥: {e}")

def test_augmentation_features():
    """æµ‹è¯•å¢å¼ºåŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•å¢å¼ºåŠŸèƒ½")
    
    cfg = DatasetConfig(
        root="../../datasets/landmarks_dataset/cooked/p0/samples_consistent",
        file_patterns=("*_t31.npz",),
        features="all",
        select_landmarks="active",
        augment=True,
        arch_align=True,
        mirror_prob=0.5,
        rotz_deg=15.0,
        trans_mm=0.5,
        ensure_constant_L=True
    )
    
    try:
        dataset = P0PointNetRegDataset(cfg)
        print(f"âœ… å¢å¼ºæ•°æ®é›†åˆ›å»ºæˆåŠŸ: {len(dataset)} ä¸ªæ ·æœ¬")
        
        # æµ‹è¯•å¤šæ¬¡è·å–åŒä¸€æ ·æœ¬ï¼ŒæŸ¥çœ‹å¢å¼ºæ•ˆæœ  
        sample1 = dataset[0]
        sample2 = dataset[0]
        
        x1, x2 = sample1['x'], sample2['x']
        diff = (x1 - x2).abs().mean().item()
        print(f"   åŒä¸€æ ·æœ¬ä¸¤æ¬¡å¢å¼ºçš„å·®å¼‚: {diff:.6f}")
        print(f"   å¢å¼ºåå½¢çŠ¶: x={x1.shape}, y={sample1['y'].shape}")
        
    except Exception as e:
        print(f"âŒ å¢å¼ºåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")

def test_dataloader():
    """æµ‹è¯•DataLoaderå…¼å®¹æ€§"""
    print("\nğŸ§ª æµ‹è¯•DataLoaderå…¼å®¹æ€§")
    
    cfg = DatasetConfig(
        root="../../datasets/landmarks_dataset/cooked/p0/samples_consistent",
        group="central",
        features="all",
        select_landmarks="active",
        augment=True,
        arch_align=True,
        mirror_prob=0.3,
        ensure_constant_L=True
    )
    
    try:
        dataset, loader = make_dataloader(cfg, batch_size=4, shuffle=False, num_workers=0)
        print(f"âœ… DataLoaderåˆ›å»ºæˆåŠŸ: {len(dataset)} ä¸ªæ ·æœ¬, {len(loader)} ä¸ªæ‰¹æ¬¡")
        
        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
        batch = next(iter(loader))
        print(f"   æ‰¹æ¬¡å½¢çŠ¶: x={batch['x'].shape}, y={batch['y'].shape}")
        print(f"   å…ƒä¿¡æ¯æ ·ä¾‹: {[meta.get('tooth_id') for meta in batch['meta'][:2]]}")
        
    except Exception as e:
        print(f"âŒ DataLoaderæµ‹è¯•å¤±è´¥: {e}")

def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print("\nğŸ§ª æµ‹è¯•é”™è¯¯å¤„ç†")
    
    # æµ‹è¯•æ— æ•ˆç»„å
    try:
        cfg = DatasetConfig(
            root="../../datasets/landmarks_dataset/cooked/p0/samples_consistent",
            group="invalid_group"
        )
        dataset = P0PointNetRegDataset(cfg)
        print("âŒ åº”è¯¥æŠ›å‡ºæ— æ•ˆç»„åé”™è¯¯")
    except ValueError as e:
        print(f"âœ… æ­£ç¡®æ•è·æ— æ•ˆç»„åé”™è¯¯: {e}")
    
    # æµ‹è¯•æ— æ•ˆç‰™ä½ID
    try:
        cfg = DatasetConfig(
            root="../../datasets/landmarks_dataset/cooked/p0/samples_consistent",
            tooth_ids=["t99", "invalid"]
        )
        dataset = P0PointNetRegDataset(cfg)
        print("âŒ åº”è¯¥æŠ›å‡ºæ— æ•ˆç‰™ä½IDé”™è¯¯")
    except ValueError as e:
        print(f"âœ… æ­£ç¡®æ•è·æ— æ•ˆç‰™ä½IDé”™è¯¯: {e}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•ä¿®æ”¹åçš„p0_dataset.pyåŠŸèƒ½")
    print("=" * 60)
    
    test_group_filtering()
    test_tooth_ids_filtering()
    test_augmentation_features()
    test_dataloader()
    test_error_handling()
    
    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()