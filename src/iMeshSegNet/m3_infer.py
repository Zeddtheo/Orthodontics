# m3_infer.py
# æ¨ç†è„šæœ¬ï¼šè¯»å–åŸå§‹ STL/VTPï¼Œä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹ï¼Œè¾“å‡ºå¸¦é¢œè‰²çš„ VTP
# 
# ä½¿ç”¨ç¤ºä¾‹ï¼š
#   1. Overfit æ¨¡å‹æ¨ç†ï¼š
#      python m3_infer.py --ckpt outputs/overfit/overfit_model.pt \
#          --input datasets/landmarks_dataset/raw/1/1_L.stl \
#          --stats outputs/segmentation/stats.npz --out outputs/overfit/infer
#
#   2. æ­£å¸¸è®­ç»ƒæ¨¡å‹æ¨ç†ï¼š
#      python m3_infer.py --ckpt outputs/segmentation/model/best.pt \
#          --input datasets/landmarks_dataset/raw/1/1_L.stl \
#          --stats outputs/segmentation/stats.npz --out outputs/segmentation/infer
#
#   3. æ‰¹é‡æ¨ç†ï¼š
#      python m3_infer.py --ckpt outputs/segmentation/model/best.pt \
#          --input datasets/landmarks_dataset/raw/ --stats outputs/segmentation/stats.npz \
#          --out outputs/segmentation/infer --ext .stl

from __future__ import annotations
import argparse
from pathlib import Path
from typing import Optional, Tuple, Dict, List

import numpy as np
import torch
import pyvista as pv

from imeshsegnet import iMeshSegNet
from m0_dataset import (
    SEG_NUM_CLASSES,
    extract_features,
    load_arch_frames,
    load_stats,
    normalize_mesh_units,
)

# å®šä¹‰é¢œè‰²æ˜ å°„ï¼ˆ15ä¸ªç±»åˆ«ï¼‰
LABEL_COLORS = {
    0:  [128, 128, 128],  # èƒŒæ™¯/ç‰™é¾ˆ - ç°è‰²
    1:  [255, 0, 0],      # ç‰™é½¿1 - çº¢è‰²
    2:  [255, 127, 0],    # ç‰™é½¿2 - æ©™è‰²
    3:  [255, 255, 0],    # ç‰™é½¿3 - é»„è‰²
    4:  [0, 255, 0],      # ç‰™é½¿4 - ç»¿è‰²
    5:  [0, 255, 255],    # ç‰™é½¿5 - é’è‰²
    6:  [0, 0, 255],      # ç‰™é½¿6 - è“è‰²
    7:  [127, 0, 255],    # ç‰™é½¿7 - ç´«è‰²
    8:  [255, 0, 255],    # ç‰™é½¿8 - å“çº¢
    9:  [255, 192, 203],  # ç‰™é½¿9 - ç²‰è‰²
    10: [165, 42, 42],    # ç‰™é½¿10 - æ£•è‰²
    11: [255, 215, 0],    # ç‰™é½¿11 - é‡‘è‰²
    12: [0, 128, 128],    # ç‰™é½¿12 - æš—é’è‰²
    13: [128, 0, 128],    # ç‰™é½¿13 - æš—ç´«è‰²
    14: [255, 140, 0],    # ç‰™é½¿14 - æš—æ©™è‰²
}

def apply_color_to_mesh(mesh: pv.PolyData, labels: np.ndarray) -> pv.PolyData:
    """æ ¹æ®é¢„æµ‹æ ‡ç­¾ä¸ºç½‘æ ¼ç€è‰²ï¼ˆcell å’Œ point çº§åˆ«ï¼‰"""
    # 1. ä¸ºæ¯ä¸ª cell ç”Ÿæˆé¢œè‰²
    cell_colors = np.zeros((len(labels), 3), dtype=np.uint8)
    for label_id, color in LABEL_COLORS.items():
        mask = labels == label_id
        cell_colors[mask] = color
    
    # 2. å°†é¢œè‰²æ·»åŠ åˆ° cell_data
    mesh.cell_data["RGB"] = cell_colors
    mesh.cell_data["PredLabel"] = labels
    
    # 3. å¿«é€Ÿå°† cell æ•°æ®è½¬æ¢ä¸º point æ•°æ®ï¼ˆä½¿ç”¨ PyVista å†…ç½®æ–¹æ³•ï¼‰
    mesh_with_point_data = mesh.cell_data_to_point_data()
    
    # 4. å¤åˆ¶è½¬æ¢åçš„ point æ•°æ®åˆ°åŸç½‘æ ¼
    mesh.point_data["RGB"] = mesh_with_point_data.point_data["RGB"]
    mesh.point_data["PredLabel"] = mesh_with_point_data.point_data["PredLabel"]
    
    return mesh


# ---------------- Utils ----------------
def _lookup_arch_frame(stem: str, frames: Dict[str, torch.Tensor]) -> Optional[torch.Tensor]:
    if not frames:
        return None
    if stem in frames:
        return frames[stem]
    base = stem.split("_")[0]
    return frames.get(base)


def load_pipeline_meta(ckpt_path: Path, args=None):
    """
    åŠ è½½ checkpoint ä¸­çš„ pipeline å…ƒæ•°æ®å¥‘çº¦
    
    ä¼˜å…ˆçº§ï¼šCLI å‚æ•° > checkpoint ä¸­çš„ pipeline > é»˜è®¤å€¼
    
    Returns:
        (checkpoint, pipeline_meta): checkpoint å­—å…¸å’Œè§£æåçš„ pipeline å…ƒæ•°æ®
    """
    # åŠ è½½ checkpoint
    try:
        ckpt = torch.load(str(ckpt_path), map_location="cpu", weights_only=True)
    except:
        ckpt = torch.load(str(ckpt_path), map_location="cpu", weights_only=False)
    
    # æå– pipeline é…ç½®
    P = ckpt.get("pipeline", {}) if isinstance(ckpt, dict) else {}
    
    # è¾…åŠ©å‡½æ•°ï¼šæŒ‰ä¼˜å…ˆçº§è·å–å‚æ•°
    def get(key, default=None):
        # CLI å‚æ•°ä¼˜å…ˆ
        if args and hasattr(args, key) and getattr(args, key) is not None:
            return getattr(args, key)
        # checkpoint ä¸­çš„é…ç½®
        if key in P:
            return P[key]
        # é»˜è®¤å€¼
        return default
    
    # æ„å»º pipeline å…ƒæ•°æ®
    zscore_cfg = P.get("zscore", {}) if isinstance(P.get("zscore"), dict) else {}
    feature_layout = P.get("feature_layout", {}) if isinstance(P.get("feature_layout"), dict) else {}
    
    meta = {
        # Z-score æ ‡å‡†åŒ–
        "zscore_apply": zscore_cfg.get("apply", True),
        "mean": np.array(zscore_cfg.get("mean")) if zscore_cfg.get("mean") else None,
        "std": np.array(zscore_cfg.get("std")) if zscore_cfg.get("std") else None,
        
        # å‡ ä½•é¢„å¤„ç†
        "centered": get("centered", True),
        "div_by_diag": get("div_by_diag", False),
        "use_frame": get("use_frame", False),
        
        # é‡‡æ ·ç­–ç•¥
        "sampler": get("sampler", "random"),
        "sample_cells": get("sample_cells", 6000),
        "target_cells": get("target_cells", 10000),
        
        # ç‰¹å¾å¸ƒå±€ï¼ˆç”¨äºæ—‹è½¬å¯¹é½ï¼‰
        "rotate_blocks": feature_layout.get("rotate_blocks", []),
        
        # éšæœºç§å­
        "seed": get("seed", 42),
        
        # è®­ç»ƒä¿¡æ¯
        "train_sample_ids_path": ckpt.get("train_sample_ids_path", None),
    }
    
    # æ‰“å°åŠ è½½çš„é…ç½®
    print(f"\nğŸ“‹ Pipeline å¥‘çº¦:")
    print(f"   Z-score: {'âœ“' if meta['zscore_apply'] else 'âœ—'} (mean shape: {meta['mean'].shape if meta['mean'] is not None else 'N/A'})")
    print(f"   Centered: {meta['centered']}, Div by diag: {meta['div_by_diag']}")
    print(f"   Use frame: {meta['use_frame']}, Sampler: {meta['sampler']}")
    print(f"   Target cells: {meta['target_cells']}, Sample cells: {meta['sample_cells']}")
    
    return ckpt, meta


@torch.no_grad()
def _load_model_with_contract(ckpt_path: Path, device: torch.device, args=None) -> Tuple[iMeshSegNet, dict]:
    """
    åŠ è½½æ¨¡å‹å¹¶éªŒè¯ pipeline å¥‘çº¦
    
    Returns:
        (model, pipeline_meta): åŠ è½½çš„æ¨¡å‹å’Œ pipeline å…ƒæ•°æ®
    """
    ckpt, meta = load_pipeline_meta(ckpt_path, args)
    
    # è·å–æ¨¡å‹é…ç½®
    num_classes = ckpt.get("num_classes", SEG_NUM_CLASSES)
    in_channels = ckpt.get("in_channels", 15)
    
    print(f"\nğŸ—ï¸  æ¨¡å‹é…ç½®:")
    print(f"   Num classes: {num_classes}")
    print(f"   In channels: {in_channels}")
    
    # åˆ›å»ºæ¨¡å‹
    model = iMeshSegNet(
        num_classes=num_classes,
        glm_impl="edgeconv",
        k_short=6,
        k_long=12,
        with_dropout=False,
    )
    
    # åŠ è½½æƒé‡
    if isinstance(ckpt, dict):
        if "state_dict" in ckpt:
            model.load_state_dict(ckpt["state_dict"])
        elif "model_state_dict" in ckpt:
            model.load_state_dict(ckpt["model_state_dict"])
        elif "model" in ckpt:
            model.load_state_dict(ckpt["model"])
        else:
            model.load_state_dict(ckpt)
    else:
        model.load_state_dict(ckpt)
    
    model.to(device).eval()
    
    # éªŒè¯å¥‘çº¦
    print(f"\nâœ… å¥‘çº¦éªŒè¯:")
    print(f"   æ¨¡å‹è¾“å‡ºç»´åº¦ä¸ num_classes ä¸€è‡´: {num_classes}")
    print(f"   ç‰¹å¾è¾“å…¥ç»´åº¦: {in_channels}")
    
    # æ·»åŠ  num_classes å’Œ in_channels åˆ° meta
    meta["num_classes"] = num_classes
    meta["in_channels"] = in_channels
    
    return model, meta


@torch.no_grad()
def _load_model(ckpt: Path, num_classes: int, device: torch.device) -> iMeshSegNet:
    model = iMeshSegNet(
        num_classes=num_classes,
        glm_impl="edgeconv",
        k_short=6,
        k_long=12,
        with_dropout=False,
    )
    # å…¼å®¹ä¸åŒçš„ PyTorch ç‰ˆæœ¬
    try:
        state = torch.load(str(ckpt), map_location="cpu", weights_only=True)
    except:
        state = torch.load(str(ckpt), map_location="cpu", weights_only=False)
    
    # å¤„ç†ä¸åŒçš„ checkpoint æ ¼å¼
    if isinstance(state, dict):
        if "model_state_dict" in state:
            model.load_state_dict(state["model_state_dict"])
        elif "model" in state:
            model.load_state_dict(state["model"])
        elif "state_dict" in state:
            model.load_state_dict(state["state_dict"])
        else:
            model.load_state_dict(state)
    else:
        model.load_state_dict(state)
    
    model.to(device).eval()
    return model

def _subset_cells(mesh: pv.PolyData, cell_ids: np.ndarray) -> pv.PolyData:
    # ä» decimated ç½‘æ ¼ä¸­æŠ½å–è‹¥å¹² cell ç»„æˆä¸€ä¸ªä½åˆ†è¾¨ç‡çš„ç²—ç³™ç½‘æ ¼
    sub = mesh.extract_cells(cell_ids.astype(np.int32))
    sub = sub.clean()  # å»æ‰æ‚¬æŒ‚æ‹“æ‰‘ç­‰
    return sub

def _infer_single_mesh(
    mesh_path: Path,
    model: iMeshSegNet,
    pipeline_meta: dict,
    arch_frames: Dict[str, torch.Tensor],
    device: torch.device,
    num_classes: int,
) -> Tuple[pv.PolyData, np.ndarray]:
    """
    åº”ç”¨ pipeline å¥‘çº¦è¿›è¡Œæ¨ç†
    
    Args:
        mesh_path: è¾“å…¥ç½‘æ ¼è·¯å¾„
        model: åŠ è½½çš„æ¨¡å‹
        pipeline_meta: ä» checkpoint è¯»å–çš„ pipeline é…ç½®ï¼ˆåŒ…å« mean/std/sampler/sample_cells/target_cells/use_frame/rotate_blocks ç­‰ï¼‰
        arch_frames: å¯é€‰çš„ arch frame å­—å…¸ï¼ˆå¦‚æœ pipeline_meta["use_frame"]=True åˆ™ä½¿ç”¨ï¼‰
        device: æ¨ç†è®¾å¤‡
        num_classes: ç±»åˆ«æ•°é‡
    
    Returns:
        sample_mesh:  é‡‡æ ·åçš„ç²—ç³™ç½‘æ ¼ï¼ˆç”¨äºè½ç›˜å±•ç¤ºï¼‰
        pred_labels:  (Ns,) é€ cell é¢„æµ‹
    """
    # ä» pipeline_meta æå–å‚æ•°
    mean = pipeline_meta["mean"]
    std = pipeline_meta["std"]
    target_cells = pipeline_meta["target_cells"]
    sample_cells = pipeline_meta["sample_cells"]
    sampler = pipeline_meta["sampler"]
    use_frame = pipeline_meta["use_frame"]
    rotate_blocks = pipeline_meta["rotate_blocks"]
    
    mesh = pv.read(str(mesh_path))
    
    # 1) å‡ ä½•é¢„å¤„ç†ï¼ˆä¸è®­ç»ƒå¥‘çº¦ä¸€è‡´ï¼‰
    if pipeline_meta["centered"]:
        mesh.points -= mesh.center
        
    if pipeline_meta["div_by_diag"]:
        mesh, scale_factor, diag_before, diag_after = normalize_mesh_units(mesh)
        if scale_factor != 1.0:
            print(
                f"  -> scaled {mesh_path.name} from diag={diag_before:.4f} to {diag_after:.2f} (mm)",
                flush=True,
            )
    else:
        diag_after = 1.0
        
    mesh = mesh.triangulate()

    # 2) ç½‘æ ¼æŠ½å–ï¼ˆæŠŠ cell æ•°é‡å‹åˆ° target_cells é™„è¿‘ï¼‰
    if mesh.n_cells > target_cells:
        reduction = 1.0 - (target_cells / float(mesh.n_cells))
        mesh = mesh.decimate_pro(reduction, feature_angle=45, preserve_topology=True)

    # 3) ç‰¹å¾æå–ï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼š9ç‚¹åæ ‡ + 3æ³•å‘ + 3ç›¸å¯¹ä½ç½® = 15Dï¼‰
    feats = extract_features(mesh).astype(np.float32)        # (Nd, 15)
    pos_raw = mesh.cell_centers().points.astype(np.float32)  # (Nd, 3)
    scale_pos = diag_after if diag_after > 1e-6 else 1.0
    pos_raw = pos_raw / scale_pos
    Nd = feats.shape[0]

    # 4) é‡‡æ ·åˆ° sample_cellsï¼ˆæ ¹æ® pipeline å¥‘çº¦é€‰æ‹©é‡‡æ ·ç­–ç•¥ï¼‰
    if Nd > sample_cells:
        if sampler == "random":
            # éšæœºé‡‡æ ·
            ids = np.random.permutation(Nd)[:sample_cells]
        elif sampler == "fps":
            # FPS é‡‡æ ·ï¼ˆéœ€è¦å®ç°æˆ–è·³è¿‡ï¼‰
            print(f"  [Warning] FPS sampler not implemented, falling back to random")
            ids = np.random.permutation(Nd)[:sample_cells]
        else:
            raise ValueError(f"Unknown sampler: {sampler}")
            
        feats = feats[ids]
        pos_raw = pos_raw[ids]
        sample_mesh = _subset_cells(mesh, ids)
        # è½¬æ¢ä¸º PolyData ä»¥ä¾¿ä¿å­˜ä¸º VTP
        sample_mesh = sample_mesh.cast_to_unstructured_grid().extract_surface()
    else:
        sample_mesh = mesh

    # 5) z-scoreï¼ˆä¸è®­ç»ƒ stats ä¸€è‡´ï¼‰
    feats_t = torch.from_numpy(feats)  # (Ns,15)
    feats_t = (feats_t - torch.from_numpy(mean)) / torch.from_numpy(std)
    
    # 6) åº”ç”¨ arch frameï¼ˆå¦‚æœ pipeline å¥‘çº¦è¦æ±‚ï¼‰
    pos_t = torch.from_numpy(pos_raw)  # (Ns,3)
    if use_frame:
        frame = _lookup_arch_frame(mesh_path.stem, arch_frames)
        if frame is not None:
            # frame: (3,3), pos: (Ns,3)
            pos_t = (frame @ pos_t.T).T
            
            # æ ¹æ® rotate_blocks æ—‹è½¬ç‰¹å¾å‘é‡
            if rotate_blocks:
                # rotate_blocks = [True, True, True, True, False] è¡¨ç¤ºå‰ 4 ä¸ª block éœ€è¦æ—‹è½¬
                # block0: v0(0:3), block1: v1(3:6), block2: v2(6:9), block3: normal(9:12), block4: cent_rel(12:15)
                for i, should_rotate in enumerate(rotate_blocks):
                    if should_rotate and i < 5:
                        start_idx = i * 3
                        end_idx = start_idx + 3
                        vec_block = feats_t[:, start_idx:end_idx]  # (Ns, 3)
                        vec_block = (frame @ vec_block.T).T
                        feats_t[:, start_idx:end_idx] = vec_block
    
    # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
    feats_t = feats_t.transpose(0, 1).contiguous().unsqueeze(0)  # (1,15,Ns)
    pos_t = pos_t.transpose(0, 1).contiguous().unsqueeze(0)      # (1,3,Ns)

    feats_t = feats_t.to(device, non_blocking=True).float()
    pos_t = pos_t.to(device, non_blocking=True).float()

    # 7) æ¨ç†ï¼ˆä¸€æ¬¡å‰å‘ï¼‰
    logits = model(feats_t, pos_t)         # (1,C,Ns)
    pred = torch.argmax(logits, dim=1)     # (1,Ns)
    pred_np = pred.squeeze(0).cpu().numpy().astype(np.int32)

    # 8) åº”ç”¨é¢œè‰²æ˜ å°„åˆ°ç½‘æ ¼
    sample_mesh = apply_color_to_mesh(sample_mesh, pred_np)
    return sample_mesh, pred_np

def _gather_inputs(input_path: Path, exts: List[str]) -> List[Path]:
    if input_path.is_file():
        return [input_path]
    files = []
    for ext in exts:
        files.extend(sorted(input_path.rglob(f"*{ext}")))
    return files


# ---------------- Main ----------------
def main():
    ap = argparse.ArgumentParser("Module-3 Inference (coarse/low-res) with Pipeline Contract")
    ap.add_argument("--ckpt", type=str, required=True, help="path to best.pt (contains pipeline metadata)")
    ap.add_argument("--input", type=str, required=True, help="file or directory of new scans (.vtp/.stl)")
    ap.add_argument("--out", type=str, default="outputs/segmentation/module3_infer", help="output directory")
    ap.add_argument("--arch-frames", type=str, default=None, help="optional JSON of arch frames (3x3 or 4x4)")
    ap.add_argument("--device", type=str, default="cuda:0")
    
    # Override options (optional, defaults to checkpoint metadata)
    ap.add_argument("--num-classes", type=int, default=None, help="Override num_classes from checkpoint")
    ap.add_argument("--target-cells", type=int, default=None, help="Override target_cells from checkpoint")
    ap.add_argument("--sample-cells", type=int, default=None, help="Override sample_cells from checkpoint")
    ap.add_argument("--ext", nargs="*", default=[".vtp", ".stl"], help="valid extensions when input is a folder")
    args = ap.parse_args()

    out_dir = Path(args.out)
    out_dir.mkdir(parents=True, exist_ok=True)

    device = torch.device(args.device if (torch.cuda.is_available() or "cpu" in args.device) else "cpu")
    
    # ä½¿ç”¨æ–°çš„å¥‘çº¦åŠ è½½å™¨ï¼ˆä» checkpoint è¯»å– pipeline é…ç½®ï¼‰
    model, pipeline_meta = _load_model_with_contract(Path(args.ckpt), device, args)
    
    # æ‰“å° pipeline é…ç½®ä¿¡æ¯
    print(f"[Pipeline Contract]")
    print(f"  zscore: mean shape={pipeline_meta['mean'].shape}, std shape={pipeline_meta['std'].shape}")
    print(f"  sampler: {pipeline_meta['sampler']}")
    print(f"  sample_cells: {pipeline_meta['sample_cells']}")
    print(f"  target_cells: {pipeline_meta['target_cells']}")
    print(f"  use_frame: {pipeline_meta['use_frame']}")
    print(f"  rotate_blocks: {pipeline_meta['rotate_blocks']}")
    print(f"  centered: {pipeline_meta['centered']}")
    print(f"  div_by_diag: {pipeline_meta['div_by_diag']}")
    
    num_classes = pipeline_meta["num_classes"]
    
    # åŠ è½½ arch framesï¼ˆå¦‚æœ pipeline å¥‘çº¦éœ€è¦ï¼‰
    arch_frames = {}
    if pipeline_meta["use_frame"]:
        if args.arch_frames:
            arch_frames = load_arch_frames(Path(args.arch_frames))
        else:
            print(f"[Warning] Pipelineå¥‘çº¦è¦æ±‚ use_frame=Trueï¼Œä½†æœªæä¾› --arch-frames å‚æ•°")

    inputs = _gather_inputs(Path(args.input), [e.lower() for e in args.ext])
    if not inputs:
        raise FileNotFoundError(f"No input files found under: {args.input}")

    print(f"\n[Infer] files={len(inputs)}  device={device}")

    for f in inputs:
        try:
            sample_mesh, pred = _infer_single_mesh(
                mesh_path=f,
                model=model,
                pipeline_meta=pipeline_meta,
                arch_frames=arch_frames,
                device=device,
                num_classes=num_classes,
            )
            # å¯¼å‡ºï¼šå¸¦é¢œè‰²çš„ VTPï¼ˆå« RGB å’Œ PredLabelï¼‰ä¸é¢„æµ‹æ ‡ç­¾ NPY
            stem = f.stem
            out_npy = out_dir / f"{stem}_pred.npy"
            out_mesh = out_dir / f"{stem}_colored.vtp"

            sample_mesh.save(str(out_mesh), binary=True)
            np.save(str(out_npy), pred)
            
            # ç»Ÿè®¡é¢„æµ‹çš„ç±»åˆ«åˆ†å¸ƒ
            unique_labels, counts = np.unique(pred, return_counts=True)
            label_dist = ", ".join([f"L{lbl}:{cnt}" for lbl, cnt in zip(unique_labels, counts)])
            print(f"  âœ“ {stem} -> {out_mesh.name} (cells={sample_mesh.n_cells}, labels=[{label_dist}])")
        except Exception as e:
            print(f"  âœ— {f.name} failed: {e}")

    print(f"[Done] outputs in: {out_dir.resolve()}")


if __name__ == "__main__":
    torch.backends.cudnn.benchmark = True
    main()
