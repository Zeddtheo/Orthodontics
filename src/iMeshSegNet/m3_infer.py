# m3_infer.py
# æŽ¨ç†è„šæœ¬ï¼šè¯»å–åŽŸå§‹ STL/VTPï¼Œä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡åž‹é¢„æµ‹ï¼Œè¾“å‡ºå¸¦é¢œè‰²çš„ VTP
# 
# ä½¿ç”¨ç¤ºä¾‹ï¼š
#   1. Overfit æ¨¡åž‹æŽ¨ç†ï¼š
#      python m3_infer.py --ckpt outputs/overfit/overfit_model.pt \
#          --input datasets/landmarks_dataset/raw/1/1_L.stl \
#          --stats outputs/segmentation/stats.npz --out outputs/overfit/infer
#
#   2. æ­£å¸¸è®­ç»ƒæ¨¡åž‹æŽ¨ç†ï¼š
#      python m3_infer.py --ckpt outputs/segmentation/model/best.pt \
#          --input datasets/landmarks_dataset/raw/1/1_L.stl \
#          --stats outputs/segmentation/stats.npz --out outputs/segmentation/infer
#
#   3. æ‰¹é‡æŽ¨ç†ï¼š
#      python m3_infer.py --ckpt outputs/segmentation/model/best.pt \
#          --input datasets/landmarks_dataset/raw/ --stats outputs/segmentation/stats.npz \
#          --out outputs/segmentation/infer --ext .stl

from __future__ import annotations
import argparse
from pathlib import Path
from typing import Optional, Tuple, Dict, List

import numpy as np
import torch
import pyvista as pv

from imeshsegnet import iMeshSegNet
from m0_dataset import (
    SEG_NUM_CLASSES,
    extract_features,
    load_arch_frames,
    load_stats,
    normalize_mesh_units,
)

# å®šä¹‰é¢œè‰²æ˜ å°„ï¼ˆ15ä¸ªç±»åˆ«ï¼‰
LABEL_COLORS = {
    0:  [128, 128, 128],  # èƒŒæ™¯/ç‰™é¾ˆ - ç°è‰²
    1:  [255, 0, 0],      # ç‰™é½¿1 - çº¢è‰²
    2:  [255, 127, 0],    # ç‰™é½¿2 - æ©™è‰²
    3:  [255, 255, 0],    # ç‰™é½¿3 - é»„è‰²
    4:  [0, 255, 0],      # ç‰™é½¿4 - ç»¿è‰²
    5:  [0, 255, 255],    # ç‰™é½¿5 - é’è‰²
    6:  [0, 0, 255],      # ç‰™é½¿6 - è“è‰²
    7:  [127, 0, 255],    # ç‰™é½¿7 - ç´«è‰²
    8:  [255, 0, 255],    # ç‰™é½¿8 - å“çº¢
    9:  [255, 192, 203],  # ç‰™é½¿9 - ç²‰è‰²
    10: [165, 42, 42],    # ç‰™é½¿10 - æ£•è‰²
    11: [255, 215, 0],    # ç‰™é½¿11 - é‡‘è‰²
    12: [0, 128, 128],    # ç‰™é½¿12 - æš—é’è‰²
    13: [128, 0, 128],    # ç‰™é½¿13 - æš—ç´«è‰²
    14: [255, 140, 0],    # ç‰™é½¿14 - æš—æ©™è‰²
}

def apply_color_to_mesh(mesh: pv.PolyData, labels: np.ndarray) -> pv.PolyData:
    """æ ¹æ®é¢„æµ‹æ ‡ç­¾ä¸ºç½‘æ ¼ç€è‰²ï¼ˆcell å’Œ point çº§åˆ«ï¼‰"""
    # 1. ä¸ºæ¯ä¸ª cell ç”Ÿæˆé¢œè‰²
    cell_colors = np.zeros((len(labels), 3), dtype=np.uint8)
    for label_id, color in LABEL_COLORS.items():
        mask = labels == label_id
        cell_colors[mask] = color
    
    # 2. å°†é¢œè‰²æ·»åŠ åˆ° cell_data
    mesh.cell_data["RGB"] = cell_colors
    mesh.cell_data["PredLabel"] = labels
    
    # 3. å¿«é€Ÿå°† cell æ•°æ®è½¬æ¢ä¸º point æ•°æ®ï¼ˆä½¿ç”¨ PyVista å†…ç½®æ–¹æ³•ï¼‰
    mesh_with_point_data = mesh.cell_data_to_point_data()
    
    # 4. å¤åˆ¶è½¬æ¢åŽçš„ point æ•°æ®åˆ°åŽŸç½‘æ ¼
    mesh.point_data["RGB"] = mesh_with_point_data.point_data["RGB"]
    mesh.point_data["PredLabel"] = mesh_with_point_data.point_data["PredLabel"]
    
    return mesh


# ---------------- Utils ----------------
def _lookup_arch_frame(stem: str, frames: Dict[str, torch.Tensor]) -> Optional[torch.Tensor]:
    if not frames:
        return None
    if stem in frames:
        return frames[stem]
    base = stem.split("_")[0]
    return frames.get(base)


def load_pipeline_meta(ckpt_path: Path, args=None):
    """
    åŠ è½½ checkpoint ä¸­çš„ pipeline å…ƒæ•°æ®å¥‘çº¦
    
    ä¼˜å…ˆçº§ï¼šCLI å‚æ•° > checkpoint ä¸­çš„ pipeline > é»˜è®¤å€¼
    
    Returns:
        (checkpoint, pipeline_meta): checkpoint å­—å…¸å’Œè§£æžåŽçš„ pipeline å…ƒæ•°æ®
    """
    # åŠ è½½ checkpoint
    try:
        ckpt = torch.load(str(ckpt_path), map_location="cpu", weights_only=True)
    except:
        ckpt = torch.load(str(ckpt_path), map_location="cpu", weights_only=False)
    
    # æå– pipeline é…ç½®
    P = ckpt.get("pipeline", {}) if isinstance(ckpt, dict) else {}
    
    # è¾…åŠ©å‡½æ•°ï¼šæŒ‰ä¼˜å…ˆçº§èŽ·å–å‚æ•°
    def get(key, default=None):
        # CLI å‚æ•°ä¼˜å…ˆ
        if args and hasattr(args, key) and getattr(args, key) is not None:
            return getattr(args, key)
        # checkpoint ä¸­çš„é…ç½®
        if key in P:
            return P[key]
        # é»˜è®¤å€¼
        return default
    
    # æž„å»º pipeline å…ƒæ•°æ®
    zscore_cfg = P.get("zscore", {}) if isinstance(P.get("zscore"), dict) else {}
    feature_layout = P.get("feature_layout", {}) if isinstance(P.get("feature_layout"), dict) else {}
    
    meta = {
        # Z-score æ ‡å‡†åŒ–
        "zscore_apply": zscore_cfg.get("apply", True),
        "mean": np.array(zscore_cfg.get("mean")) if zscore_cfg.get("mean") else None,
        "std": np.array(zscore_cfg.get("std")) if zscore_cfg.get("std") else None,
        
        # å‡ ä½•é¢„å¤„ç†
        "centered": get("centered", True),
        "div_by_diag": get("div_by_diag", False),
        "use_frame": get("use_frame", False),
        
        # é‡‡æ ·ç­–ç•¥
        "sampler": get("sampler", "random"),
        "sample_cells": get("sample_cells", 6000),
        "target_cells": get("target_cells", 10000),
        
        # ç‰¹å¾å¸ƒå±€ï¼ˆç”¨äºŽæ—‹è½¬å¯¹é½ï¼‰
        "rotate_blocks": feature_layout.get("rotate_blocks", []),
        
        # éšæœºç§å­
        "seed": get("seed", 42),
        
        # è®­ç»ƒä¿¡æ¯
        "train_sample_ids_path": ckpt.get("train_sample_ids_path", None),
    }
    
    # æ‰“å°åŠ è½½çš„é…ç½®
    print(f"\nðŸ“‹ Pipeline å¥‘çº¦:")
    print(f"   Z-score: {'âœ“' if meta['zscore_apply'] else 'âœ—'} (mean shape: {meta['mean'].shape if meta['mean'] is not None else 'N/A'})")
    print(f"   Centered: {meta['centered']}, Div by diag: {meta['div_by_diag']}")
    print(f"   Use frame: {meta['use_frame']}, Sampler: {meta['sampler']}")
    print(f"   Target cells: {meta['target_cells']}, Sample cells: {meta['sample_cells']}")
    
    return ckpt, meta


@torch.no_grad()
def _load_model_with_contract(ckpt_path: Path, device: torch.device, args=None) -> Tuple[iMeshSegNet, dict]:
    """
    åŠ è½½æ¨¡åž‹å¹¶éªŒè¯ pipeline å¥‘çº¦
    
    Returns:
        (model, pipeline_meta): åŠ è½½çš„æ¨¡åž‹å’Œ pipeline å…ƒæ•°æ®
    """
    ckpt, meta = load_pipeline_meta(ckpt_path, args)
    
    # èŽ·å–æ¨¡åž‹é…ç½®
    num_classes = ckpt.get("num_classes", SEG_NUM_CLASSES)
    in_channels = ckpt.get("in_channels", 15)
    
    print(f"\nðŸ—ï¸  æ¨¡åž‹é…ç½®:")
    print(f"   Num classes: {num_classes}")
    print(f"   In channels: {in_channels}")
    
    # åˆ›å»ºæ¨¡åž‹
    model = iMeshSegNet(
        num_classes=num_classes,
        glm_impl="edgeconv",
        k_short=6,
        k_long=12,
        with_dropout=False,
    )
    
    # åŠ è½½æƒé‡
    if isinstance(ckpt, dict):
        if "state_dict" in ckpt:
            model.load_state_dict(ckpt["state_dict"])
        elif "model_state_dict" in ckpt:
            model.load_state_dict(ckpt["model_state_dict"])
        elif "model" in ckpt:
            model.load_state_dict(ckpt["model"])
        else:
            model.load_state_dict(ckpt)
    else:
        model.load_state_dict(ckpt)
    
    model.to(device).eval()
    
    # éªŒè¯å¥‘çº¦
    print(f"\nâœ… å¥‘çº¦éªŒè¯:")
    print(f"   æ¨¡åž‹è¾“å‡ºç»´åº¦ä¸Ž num_classes ä¸€è‡´: {num_classes}")
    print(f"   ç‰¹å¾è¾“å…¥ç»´åº¦: {in_channels}")
    
    return model, meta


@torch.no_grad()
def _load_model(ckpt: Path, num_classes: int, device: torch.device) -> iMeshSegNet:
    model = iMeshSegNet(
        num_classes=num_classes,
        glm_impl="edgeconv",
        k_short=6,
        k_long=12,
        with_dropout=False,
    )
    # å…¼å®¹ä¸åŒçš„ PyTorch ç‰ˆæœ¬
    try:
        state = torch.load(str(ckpt), map_location="cpu", weights_only=True)
    except:
        state = torch.load(str(ckpt), map_location="cpu", weights_only=False)
    
    # å¤„ç†ä¸åŒçš„ checkpoint æ ¼å¼
    if isinstance(state, dict):
        if "model_state_dict" in state:
            model.load_state_dict(state["model_state_dict"])
        elif "model" in state:
            model.load_state_dict(state["model"])
        elif "state_dict" in state:
            model.load_state_dict(state["state_dict"])
        else:
            model.load_state_dict(state)
    else:
        model.load_state_dict(state)
    
    model.to(device).eval()
    return model

def _subset_cells(mesh: pv.PolyData, cell_ids: np.ndarray) -> pv.PolyData:
    # ä»Ž decimated ç½‘æ ¼ä¸­æŠ½å–è‹¥å¹² cell ç»„æˆä¸€ä¸ªä½Žåˆ†è¾¨çŽ‡çš„ç²—ç³™ç½‘æ ¼
    sub = mesh.extract_cells(cell_ids.astype(np.int32))
    sub = sub.clean()  # åŽ»æŽ‰æ‚¬æŒ‚æ‹“æ‰‘ç­‰
    return sub

def _infer_single_mesh(
    mesh_path: Path,
    model: iMeshSegNet,
    mean: np.ndarray,
    std: np.ndarray,
    arch_frames: Dict[str, torch.Tensor],
    device: torch.device,
    target_cells: int,
    sample_cells: int,
    num_classes: int,
) -> Tuple[pv.PolyData, np.ndarray]:
    """
    Returns:
        sample_mesh:  é‡‡æ ·åŽçš„ç²—ç³™ç½‘æ ¼ï¼ˆç”¨äºŽè½ç›˜å±•ç¤ºï¼‰
        pred_labels:  (Ns,) é€ cell é¢„æµ‹
    """
    mesh = pv.read(str(mesh_path))
    mesh.points -= mesh.center
    mesh, scale_factor, diag_before, diag_after = normalize_mesh_units(mesh)
    if scale_factor != 1.0:
        print(
            f"  -> scaled {mesh_path.name} from diag={diag_before:.4f} to {diag_after:.2f} (mm)",
            flush=True,
        )
    mesh = mesh.triangulate()

    # 2) ç½‘æ ¼æŠ½å–ï¼ˆæŠŠ cell æ•°é‡åŽ‹åˆ° target_cells é™„è¿‘ï¼‰
    if mesh.n_cells > target_cells:
        reduction = 1.0 - (target_cells / float(mesh.n_cells))
        mesh = mesh.decimate_pro(reduction, feature_angle=45, preserve_topology=True)

    # 3) ç‰¹å¾æå–ï¼ˆä¸Žè®­ç»ƒä¸€è‡´ï¼š9ç‚¹åæ ‡ + 3æ³•å‘ + 3ç›¸å¯¹ä½ç½® = 15Dï¼‰
    feats = extract_features(mesh).astype(np.float32)        # (Nd, 15)
    pos_raw = mesh.cell_centers().points.astype(np.float32)  # (Nd, 3)
    scale_pos = diag_after if diag_after > 1e-6 else 1.0
    pos_raw = pos_raw / scale_pos
    Nd = feats.shape[0]

    # 4) éšæœºé‡‡æ ·åˆ° sample_cellsï¼ˆå¾—åˆ°ç²—ç³™ä½Žåˆ†è¾¨çŽ‡ç½‘æ ¼ï¼‰
    if Nd > sample_cells:
        ids = np.random.permutation(Nd)[:sample_cells]
        feats = feats[ids]
        pos_raw = pos_raw[ids]
        sample_mesh = _subset_cells(mesh, ids)
        # è½¬æ¢ä¸º PolyData ä»¥ä¾¿ä¿å­˜ä¸º VTP
        sample_mesh = sample_mesh.cast_to_unstructured_grid().extract_surface()
    else:
        sample_mesh = mesh

    # 5) z-scoreï¼ˆä¸Žè®­ç»ƒ stats ä¸€è‡´ï¼‰ï¼Œä»¥åŠ arch frameï¼ˆè‹¥å¯ç”¨ï¼‰
    feats_t = torch.from_numpy(feats)  # (Ns,15)
    feats_t = (feats_t - torch.from_numpy(mean)) / torch.from_numpy(std)
    feats_t = feats_t.transpose(0, 1).contiguous().unsqueeze(0)  # (1,15,Ns)

    pos_t = torch.from_numpy(pos_raw)  # (Ns,3)
    frame = _lookup_arch_frame(mesh_path.stem, arch_frames)
    if frame is not None:
        # frame: (3,3), pos: (Ns,3)
        pos_t = (frame @ pos_t.T).T
    pos_t = pos_t.transpose(0, 1).contiguous().unsqueeze(0)      # (1,3,Ns)

    feats_t = feats_t.to(device, non_blocking=True).float()
    pos_t = pos_t.to(device, non_blocking=True).float()

    # 6) æŽ¨ç†ï¼ˆä¸€æ¬¡å‰å‘ï¼‰
    logits = model(feats_t, pos_t)         # (1,C,Ns)
    pred = torch.argmax(logits, dim=1)     # (1,Ns)
    pred_np = pred.squeeze(0).cpu().numpy().astype(np.int32)

    # 7) åº”ç”¨é¢œè‰²æ˜ å°„åˆ°ç½‘æ ¼
    sample_mesh = apply_color_to_mesh(sample_mesh, pred_np)
    return sample_mesh, pred_np

def _gather_inputs(input_path: Path, exts: List[str]) -> List[Path]:
    if input_path.is_file():
        return [input_path]
    files = []
    for ext in exts:
        files.extend(sorted(input_path.rglob(f"*{ext}")))
    return files


# ---------------- Main ----------------
def main():
    ap = argparse.ArgumentParser("Module-3 Inference (coarse/low-res)")
    ap.add_argument("--ckpt", type=str, required=True, help="path to best.pt")
    ap.add_argument("--input", type=str, required=True, help="file or directory of new scans (.vtp/.stl)")
    ap.add_argument("--stats", type=str, required=True, help="stats.npz for z-score (same as training)")
    ap.add_argument("--out", type=str, default="outputs/segmentation/module3_infer", help="output directory")
    ap.add_argument("--arch-frames", type=str, default=None, help="optional JSON of arch frames (3x3 or 4x4)")
    ap.add_argument("--device", type=str, default="cuda:0")
    ap.add_argument("--num-classes", type=int, default=SEG_NUM_CLASSES)
    ap.add_argument("--target-cells", type=int, default=10000, help="Target cells after decimation (same as training)")
    ap.add_argument("--sample-cells", type=int, default=9000, help="Sample cells for inference (same as training)")
    ap.add_argument("--ext", nargs="*", default=[".vtp", ".stl"], help="valid extensions when input is a folder")
    args = ap.parse_args()

    out_dir = Path(args.out)
    out_dir.mkdir(parents=True, exist_ok=True)

    device = torch.device(args.device if (torch.cuda.is_available() or "cpu" in args.device) else "cpu")
    model = _load_model(Path(args.ckpt), num_classes=args.num_classes, device=device)

    mean, std = load_stats(Path(args.stats))
    arch_frames = load_arch_frames(Path(args.arch_frames)) if args.arch_frames else {}

    inputs = _gather_inputs(Path(args.input), [e.lower() for e in args.ext])
    if not inputs:
        raise FileNotFoundError(f"No input files found under: {args.input}")

    print(f"[Infer] files={len(inputs)}  device={device}  target_cells={args.target_cells}  sample_cells={args.sample_cells}")

    for f in inputs:
        try:
            sample_mesh, pred = _infer_single_mesh(
                mesh_path=f,
                model=model,
                mean=mean,
                std=std,
                arch_frames=arch_frames,
                device=device,
                target_cells=args.target_cells,
                sample_cells=args.sample_cells,
                num_classes=args.num_classes,
            )
            # å¯¼å‡ºï¼šå¸¦é¢œè‰²çš„ VTPï¼ˆå« RGB å’Œ PredLabelï¼‰ä¸Žé¢„æµ‹æ ‡ç­¾ NPY
            stem = f.stem
            out_npy = out_dir / f"{stem}_pred.npy"
            out_mesh = out_dir / f"{stem}_colored.vtp"

            sample_mesh.save(str(out_mesh), binary=True)
            np.save(str(out_npy), pred)
            
            # ç»Ÿè®¡é¢„æµ‹çš„ç±»åˆ«åˆ†å¸ƒ
            unique_labels, counts = np.unique(pred, return_counts=True)
            label_dist = ", ".join([f"L{lbl}:{cnt}" for lbl, cnt in zip(unique_labels, counts)])
            print(f"  âœ“ {stem} -> {out_mesh.name} (cells={sample_mesh.n_cells}, labels=[{label_dist}])")
        except Exception as e:
            print(f"  âœ— {f.name} failed: {e}")

    print(f"[Done] outputs in: {out_dir.resolve()}")


if __name__ == "__main__":
    torch.backends.cudnn.benchmark = True
    main()
