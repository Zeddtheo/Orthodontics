"""
æµ‹è¯• m1_train.py çš„ Linux å…¼å®¹æ€§
æ£€æŸ¥ AMPã€GradScaler ç­‰ç»„ä»¶çš„å¯¼å…¥å’Œä½¿ç”¨
"""
import sys
import torch

print("=" * 70)
print("ğŸ” æ£€æŸ¥ PyTorch AMP å…¼å®¹æ€§")
print("=" * 70)
print()

print(f"ğŸ“¦ PyTorch ç‰ˆæœ¬: {torch.__version__}")
print(f"ğŸ–¥ï¸  CUDA å¯ç”¨: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"ğŸ® CUDA ç‰ˆæœ¬: {torch.version.cuda}")
    print(f"ğŸ“Š GPU æ•°é‡: {torch.cuda.device_count()}")
    if torch.cuda.device_count() > 0:
        print(f"ğŸ¯ å½“å‰ GPU: {torch.cuda.get_device_name(0)}")
print()

# æµ‹è¯•å¯¼å…¥
print("ğŸ”§ æµ‹è¯• AMP å¯¼å…¥...")

# æ–¹æ³• 1: å°è¯•å¯¼å…¥ torch.amp (PyTorch >= 1.10)
try:
    from torch.amp import autocast, GradScaler
    print("  âœ… torch.amp.autocast å¯ç”¨ (PyTorch >= 1.10)")
    amp_source = "torch.amp"
    HAS_AMP = True
except ImportError as e:
    print(f"  âŒ torch.amp ä¸å¯ç”¨: {e}")
    amp_source = None
    HAS_AMP = False

# æ–¹æ³• 2: å°è¯•å¯¼å…¥ torch.cuda.amp (PyTorch < 1.10)
if not HAS_AMP:
    try:
        from torch.cuda.amp import autocast, GradScaler
        print("  âœ… torch.cuda.amp.autocast å¯ç”¨ (PyTorch < 1.10)")
        amp_source = "torch.cuda.amp"
        HAS_AMP = True
    except ImportError as e:
        print(f"  âŒ torch.cuda.amp ä¸å¯ç”¨: {e}")

if not HAS_AMP:
    print("  âš ï¸  AMP ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPU fallback")
    amp_source = "fallback"
else:
    print(f"  ğŸ“ AMP æ¥æº: {amp_source}")

print()

# æµ‹è¯• GradScaler åˆå§‹åŒ–
print("ğŸ§ª æµ‹è¯• GradScaler åˆå§‹åŒ–...")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device_type = "cuda" if device.type == "cuda" else "cpu"

if HAS_AMP:
    try:
        # æ–°ç‰ˆ API (device å‚æ•°)
        if amp_source == "torch.amp":
            from torch.amp import GradScaler
        else:
            from torch.cuda.amp import GradScaler
        
        try:
            scaler = GradScaler(device=device_type, enabled=(device.type == "cuda"))
            print(f"  âœ… GradScaler(device='{device_type}') åˆå§‹åŒ–æˆåŠŸ (æ–°ç‰ˆ API)")
        except TypeError:
            # æ—§ç‰ˆ API (æ—  device å‚æ•°)
            scaler = GradScaler(enabled=(device.type == "cuda"))
            print(f"  âœ… GradScaler(enabled={device.type == 'cuda'}) åˆå§‹åŒ–æˆåŠŸ (æ—§ç‰ˆ API)")
        
        print(f"  ğŸ“Š Scaler enabled: {scaler.is_enabled()}")
    except Exception as e:
        print(f"  âŒ GradScaler åˆå§‹åŒ–å¤±è´¥: {e}")
else:
    print("  âš ï¸  AMP ä¸å¯ç”¨ï¼Œä½¿ç”¨ fallback GradScaler")

print()

# æµ‹è¯• autocast ä½¿ç”¨
print("ğŸ­ æµ‹è¯• autocast ä½¿ç”¨...")
if HAS_AMP and device.type == "cuda":
    try:
        # æ–°ç‰ˆ API
        if amp_source == "torch.amp":
            from torch.amp import autocast
            try:
                with autocast(device_type="cuda", enabled=True):
                    x = torch.randn(2, 3, device=device)
                    y = x * 2
                print("  âœ… autocast(device_type='cuda') å·¥ä½œæ­£å¸¸ (æ–°ç‰ˆ API)")
            except TypeError:
                # æ—§ç‰ˆ API fallback
                with autocast(enabled=True):
                    x = torch.randn(2, 3, device=device)
                    y = x * 2
                print("  âœ… autocast(enabled=True) å·¥ä½œæ­£å¸¸ (æ—§ç‰ˆ API)")
        else:
            from torch.cuda.amp import autocast
            with autocast(enabled=True):
                x = torch.randn(2, 3, device=device)
                y = x * 2
            print("  âœ… torch.cuda.amp.autocast å·¥ä½œæ­£å¸¸")
    except Exception as e:
        print(f"  âŒ autocast æµ‹è¯•å¤±è´¥: {e}")
else:
    print(f"  â„¹ï¸  è·³è¿‡ autocast æµ‹è¯• (device={device}, HAS_AMP={HAS_AMP})")

print()

# å…¼å®¹æ€§æ€»ç»“
print("=" * 70)
print("ğŸ“‹ å…¼å®¹æ€§æ€»ç»“")
print("=" * 70)
print(f"  PyTorch ç‰ˆæœ¬: {torch.__version__}")
print(f"  è®¾å¤‡: {device}")
print(f"  AMP å¯ç”¨: {HAS_AMP}")
print(f"  AMP æ¥æº: {amp_source}")

if device.type == "cpu":
    print()
    print("  â„¹ï¸  CPU æ¨¡å¼ï¼š")
    print("     - GradScaler ä¼šè¢«ç¦ç”¨ (enabled=False)")
    print("     - autocast ä¼šè¢«è·³è¿‡ (ä½¿ç”¨ nullcontext)")
    print("     - è®­ç»ƒé€Ÿåº¦è¾ƒæ…¢ä½†å…¼å®¹æ€§æœ€å¥½")

if HAS_AMP and device.type == "cuda":
    print()
    print("  âœ… GPU + AMP æ¨¡å¼ï¼š")
    print("     - æ··åˆç²¾åº¦è®­ç»ƒå·²å¯ç”¨")
    print("     - é¢„æœŸé€Ÿåº¦æå‡ 1.5-3x")
    print("     - æ˜¾å­˜å ç”¨å‡å°‘çº¦ 40%")

print()
print("ğŸ¯ ç»“è®º: m1_train.py åº”è¯¥å¯ä»¥åœ¨æ­¤ç¯å¢ƒè¿è¡Œ")
print("=" * 70)
